# 美赛机器学习算法使用指南

## 简介

本指南详细介绍如何使用本项目提供的机器学习算法模板进行美赛建模。

## 算法选择建议

### 根据问题类型选择算法

#### 1. 回归问题（预测连续值）

**适用场景：**
- 预测房价、温度、销量等连续变量
- 环境科学问题中的污染物浓度预测
- 经济指标预测

**推荐算法：**
1. **多元线性回归** - 作为基准模型，解释性强
2. **随机森林回归** - 处理非线性关系，特征重要性分析
3. **梯度提升回归** - 最高精度，竞赛常用

**代码示例：**
```python
from algorithms.regression import MultipleLinearRegressionModel
from algorithms.ensemble import RandomForestModel, GradientBoostingModel

# 线性回归
lr_model = MultipleLinearRegressionModel(normalize=True)
lr_model.fit(X_train, y_train)

# 随机森林
rf_model = RandomForestModel(task_type='regression', n_estimators=100)
rf_model.fit(X_train, y_train)

# 梯度提升
gb_model = GradientBoostingModel(task_type='regression', n_estimators=100)
gb_model.fit(X_train, y_train)
```

#### 2. 分类问题（预测类别）

**适用场景：**
- 疾病诊断（是否患病）
- 客户流失预测
- 政策效果评估（成功/失败）

**推荐算法：**
1. **逻辑回归** - 二分类首选，可解释性强
2. **随机森林分类** - 多分类问题，鲁棒性好
3. **SVM** - 高维数据分类

**代码示例：**
```python
from algorithms.classification import LogisticRegressionModel, SVMModel
from algorithms.ensemble import RandomForestModel

# 逻辑回归
log_model = LogisticRegressionModel(penalty='l2', C=1.0)
log_model.fit(X_train, y_train)

# SVM
svm_model = SVMModel(task_type='classification', kernel='rbf')
svm_model.fit(X_train, y_train)

# 随机森林
rf_model = RandomForestModel(task_type='classification', n_estimators=100)
rf_model.fit(X_train, y_train)
```

### 根据数据特点选择算法

#### 小数据集（样本数 < 1000）
- 逻辑回归、线性回归
- KNN
- 决策树

#### 中等数据集（1000 < 样本数 < 10000）
- 随机森林
- SVM
- 梯度提升

#### 大数据集（样本数 > 10000）
- 随机森林
- 梯度提升
- XGBoost

#### 高维数据（特征数很多）
- SVM
- 随机森林（自动特征选择）
- 正则化线性模型（L1/L2）

## 完整建模流程

### 第一步：数据探索

```python
from algorithms.utils import DataExplorer
import pandas as pd

# 加载数据
data = pd.read_csv('your_data.csv')

# 创建探索器
explorer = DataExplorer()

# 查看统计信息
print(explorer.summary_statistics(data))

# 可视化
explorer.plot_distributions(data)  # 分布图
explorer.plot_correlation_matrix(data)  # 相关性矩阵
explorer.plot_missing_values(data)  # 缺失值
```

### 第二步：数据预处理

```python
from algorithms.utils import DataPreprocessor

preprocessor = DataPreprocessor()

# 1. 处理缺失值
data_filled = preprocessor.handle_missing_values(data, strategy='mean')

# 2. 编码分类变量
categorical_columns = ['城市', '类别', '等级']
data_encoded = preprocessor.encode_categorical(
    data_filled, 
    method='onehot',  # 或 'label'
    columns=categorical_columns
)

# 3. 特征缩放
data_scaled = preprocessor.scale_features(
    data_encoded,
    method='standard'  # 或 'minmax', 'robust'
)

# 4. 移除异常值
data_clean = preprocessor.remove_outliers(
    data_scaled,
    method='iqr',  # 或 'zscore'
    threshold=1.5
)
```

### 第三步：特征工程

```python
# 特征选择
X = data_clean.drop('目标变量', axis=1)
y = data_clean['目标变量']

X_selected, selected_features = preprocessor.select_features(
    X, y, 
    k=10,  # 选择前10个特征
    task_type='regression',
    method='f_test'  # 或 'mutual_info'
)

print(f"选择的特征: {selected_features}")
```

### 第四步：模型训练和比较

```python
from sklearn.model_selection import train_test_split
from algorithms.utils import ModelEvaluator
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# 划分数据
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2, random_state=42
)

# 创建评估器
evaluator = ModelEvaluator()

# 定义多个模型
models = {
    '线性回归': LinearRegression(),
    '随机森林': RandomForestRegressor(n_estimators=100, random_state=42),
    '梯度提升': GradientBoostingRegressor(n_estimators=100, random_state=42)
}

# 比较模型
comparison = evaluator.compare_models(
    models, X_train, y_train, 
    cv=5, task_type='regression'
)

print(comparison)

# 选择最佳模型
best_model_name = comparison.iloc[0]['Model']
best_model = models[best_model_name]
best_model.fit(X_train, y_train)
```

### 第五步：模型评估

```python
# 预测
y_pred = best_model.predict(X_test)

# 评估指标
if task_type == 'regression':
    metrics = evaluator.evaluate_regression(y_test, y_pred)
    print("回归指标:")
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.4f}")
    
    # 可视化
    evaluator.plot_residuals(y_test, y_pred)
else:
    metrics = evaluator.evaluate_classification(y_test, y_pred)
    print("分类指标:")
    for metric, value in metrics.items():
        if isinstance(value, (int, float)):
            print(f"  {metric}: {value:.4f}")
    
    # 可视化
    evaluator.plot_confusion_matrix(y_test, y_pred)
```

### 第六步：特征重要性分析

```python
from algorithms.ensemble import RandomForestModel

# 使用随机森林获取特征重要性
rf_model = RandomForestModel(task_type='regression', n_estimators=100)
rf_model.fit(X_train, y_train)

# 获取特征重要性
importance = rf_model.get_feature_importance()
print("\n特征重要性排序:")
print(importance)

# 可视化
rf_model.plot_feature_importance(top_n=10)
```

### 第七步：模型优化

```python
from sklearn.model_selection import GridSearchCV

# 定义参数网格
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15, None],
    'min_samples_split': [2, 5, 10]
}

# 网格搜索
grid_search = GridSearchCV(
    RandomForestRegressor(random_state=42),
    param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

print(f"最优参数: {grid_search.best_params_}")
print(f"最优分数: {grid_search.best_score_:.4f}")

# 使用最优模型
final_model = grid_search.best_estimator_
```

## 美赛论文写作建议

### 1. 问题重述
- 清晰描述问题
- 明确建模目标
- 说明数据来源

### 2. 假设和约束
```
假设：
1. 数据独立同分布
2. 特征与目标变量存在稳定关系
3. 无重大外部干扰
```

### 3. 模型建立

#### 3.1 数据预处理部分
```
数据预处理包括：
1. 缺失值处理：使用均值填充
2. 异常值检测：使用IQR方法
3. 特征缩放：标准化（Z-score）
4. 类别编码：独热编码
```

#### 3.2 特征工程部分
```
特征工程策略：
1. 特征选择：使用F检验选择前K个特征
2. 特征构造：基于领域知识构造交互特征
3. 降维：PCA（如果需要）
```

#### 3.3 模型选择部分
```
模型对比：
我们比较了以下模型：
1. 线性回归：作为基准模型
2. 随机森林：处理非线性关系
3. 梯度提升：追求最高精度

评估指标：
- 回归：R²、RMSE、MAE
- 分类：准确率、精确率、召回率、F1分数

交叉验证结果：
[插入模型比较表格]

最终选择：梯度提升模型（R² = 0.92）
```

### 4. 结果分析

#### 4.1 特征重要性
```
根据随机森林分析，影响目标变量的前5个特征为：
1. 特征A：重要性 0.35
2. 特征B：重要性 0.25
3. 特征C：重要性 0.18
...

[插入特征重要性图表]
```

#### 4.2 预测结果
```
模型在测试集上的表现：
- R² = 0.92
- RMSE = 5.43
- MAE = 4.21

预测误差分布呈正态分布，表明模型稳定可靠。
[插入残差图]
```

### 5. 敏感性分析

```python
# 敏感性分析示例
import numpy as np

# 改变关键特征值
feature_to_test = '污染物排放'
original_values = X_test[feature_to_test].copy()

sensitivity_results = []
for multiplier in [0.8, 0.9, 1.0, 1.1, 1.2]:
    X_test_copy = X_test.copy()
    X_test_copy[feature_to_test] = original_values * multiplier
    y_pred_sensitivity = best_model.predict(X_test_copy)
    mean_prediction = y_pred_sensitivity.mean()
    sensitivity_results.append({
        'Multiplier': multiplier,
        'Mean_Prediction': mean_prediction,
        'Change_%': (mean_prediction / y_pred.mean() - 1) * 100
    })

sensitivity_df = pd.DataFrame(sensitivity_results)
print(sensitivity_df)
```

### 6. 模型验证

```
验证方法：
1. 交叉验证：5折交叉验证
2. 留出法：80%训练，20%测试
3. 时间验证（如适用）：使用最新数据验证

验证结果表明模型具有良好的泛化能力。
```

### 7. 结论和建议

基于模型结果提出：
1. 主要发现
2. 政策建议
3. 模型局限性
4. 未来改进方向

## 常见问题解答

### Q1: 如何选择合适的评估指标？

**回归问题：**
- R²：解释方差比例（0-1，越大越好）
- RMSE：预测误差的标准差（越小越好）
- MAE：平均绝对误差（越小越好）

**分类问题：**
- 准确率：适合类别平衡问题
- F1分数：适合类别不平衡问题
- AUC：二分类综合指标

### Q2: 如何处理类别不平衡？

```python
from sklearn.utils import resample

# 过采样少数类
minority_class = data[data['label'] == 1]
majority_class = data[data['label'] == 0]

minority_upsampled = resample(
    minority_class,
    replace=True,
    n_samples=len(majority_class),
    random_state=42
)

data_balanced = pd.concat([majority_class, minority_upsampled])
```

### Q3: 如何避免过拟合？

1. 使用交叉验证
2. 正则化（L1/L2）
3. 减少模型复杂度
4. 增加训练数据
5. 特征选择

```python
# 使用L2正则化
from sklearn.linear_model import Ridge

ridge_model = Ridge(alpha=1.0)  # alpha越大，正则化越强
ridge_model.fit(X_train, y_train)
```

### Q4: 如何提高模型性能？

1. **特征工程**：构造有意义的特征
2. **超参数调优**：网格搜索或随机搜索
3. **集成学习**：组合多个模型
4. **数据增强**：增加训练样本
5. **特征缩放**：确保所有特征在同一尺度

## 代码模板汇总

### 完整回归任务模板

```python
# 导入必要的库
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from algorithms.regression import MultipleLinearRegressionModel
from algorithms.ensemble import RandomForestModel, GradientBoostingModel
from algorithms.utils import DataPreprocessor, ModelEvaluator

# 1. 加载数据
data = pd.read_csv('data.csv')

# 2. 数据预处理
preprocessor = DataPreprocessor()
data = preprocessor.handle_missing_values(data)
data = preprocessor.remove_outliers(data)

# 3. 准备数据
X = data.drop('target', axis=1)
y = data['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. 训练模型
model = GradientBoostingModel(task_type='regression', n_estimators=100)
model.fit(X_train, y_train)

# 5. 评估
metrics = model.evaluate(X_test, y_test)
print(metrics)

# 6. 特征重要性
importance = model.get_feature_importance()
print(importance)
```

### 完整分类任务模板

```python
# 导入必要的库
import pandas as pd
from sklearn.model_selection import train_test_split
from algorithms.classification import LogisticRegressionModel
from algorithms.ensemble import RandomForestModel
from algorithms.utils import DataPreprocessor, ModelEvaluator

# 1. 加载数据
data = pd.read_csv('data.csv')

# 2. 数据预处理
preprocessor = DataPreprocessor()
data = preprocessor.handle_missing_values(data)
data = preprocessor.encode_categorical(data, method='onehot')

# 3. 准备数据
X = data.drop('target', axis=1)
y = data['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. 训练模型
model = RandomForestModel(task_type='classification', n_estimators=100)
model.fit(X_train, y_train)

# 5. 评估
metrics = model.evaluate(X_test, y_test)
print(f"Accuracy: {metrics['Accuracy']:.4f}")
print(metrics['Classification Report'])

# 6. 特征重要性
importance = model.get_feature_importance()
print(importance)
```

## 参考资源

- Scikit-learn官方文档：https://scikit-learn.org/
- 美赛官网：https://www.comap.com/
- 机器学习速查表：https://scikit-learn.org/stable/tutorial/machine_learning_map/

---

**祝美赛取得优异成绩！**
